{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените трансформации из задания 3 в качестве трансформаций датасета из практики 2.2. В этом задании можно пользоваться torch.nn, за исключением трансформаций. Покажите, как меняются лосс и метрики на трейне и на тесте в зависимости от количества и вероятностей трансформаций. Проведите обучение на большом количестве эпох. Опишите, что вы наблюдаете для каждого случая и какая есть разница, если применить трансформации. Предоставьте графики в matplotlib или tensorboard (+1 балл) в ноутбуке (в случае с tensorboard можно в отдельном окне) с наглядными примерами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from transformation import RandomCrop, RandomRotate, RandomZoom, To_tensor, Compose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imageset(Dataset):\n",
    "    def __init__(self, data_container:list[tuple], composer):\n",
    "        self.data = data_container\n",
    "        self.composer = composer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx][0]\n",
    "        if self.composer is not None:\n",
    "            image = self.composer(image)\n",
    "        image = To_tensor()(image)\n",
    "        label = np.array(self.data[idx][1])\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_csv(csv_path):\n",
    "    images_and_labels = []\n",
    "    with open(csv_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            label = row[0]\n",
    "            pixels = np.array([int(x) for x in row[1:]], dtype=np.uint8)\n",
    "            pixels = pixels.reshape(28, 28)\n",
    "            img = Image.fromarray(pixels, mode='L')  # 'L' mode for grayscale\n",
    "            images_and_labels.append((img, int(label)))\n",
    "    return images_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "prob1 = 0.25; prob2 = 0.05; prob3 = 0.05\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    notes=\"first experiment\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\":learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"rotate_prob\": prob1,\n",
    "    \"zoom_prob\": prob2,\n",
    "    \"crop_prob\": prob3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vis here: https://wandb.ai/mode-spbu/my-awesome-project/workspace?nw=nwusermode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = RandomRotate(prob1)\n",
    "t2 = RandomZoom(prob2)\n",
    "t3 = RandomCrop(prob3)\n",
    "composer = Compose([t1,t2,t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Imageset(read_image_csv(\"../../data/FashionMNIST/fashion-mnist_train.csv\"), composer)\n",
    "test_data = Imageset(read_image_csv(\"../../data/FashionMNIST/fashion-mnist_test.csv\"), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Coat\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0][0]\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {labels_map[int(label)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (base): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (head): Linear(in_features=10816, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(1,8,3),\n",
    "            nn.Conv2d(8, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.head = nn.Linear(10816, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs, targets\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_idx + 1) * len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, num_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            model.eval()\n",
    "            preds = model(inputs)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            test_loss += loss\n",
    "            num_correct += (preds.argmax(1) == targets).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    num_correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*num_correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, num_correct*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.376179  [   64/60000]\n",
      "loss: 1.469633  [ 6464/60000]\n",
      "loss: 1.334056  [12864/60000]\n",
      "loss: 1.271373  [19264/60000]\n",
      "loss: 1.160839  [25664/60000]\n",
      "loss: 0.917239  [32064/60000]\n",
      "loss: 1.101271  [38464/60000]\n",
      "loss: 0.933753  [44864/60000]\n",
      "loss: 1.338295  [51264/60000]\n",
      "loss: 1.125067  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.597868 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.164831  [   64/60000]\n",
      "loss: 0.860125  [ 6464/60000]\n",
      "loss: 0.987114  [12864/60000]\n",
      "loss: 1.020216  [19264/60000]\n",
      "loss: 0.846467  [25664/60000]\n",
      "loss: 0.976571  [32064/60000]\n",
      "loss: 1.094007  [38464/60000]\n",
      "loss: 0.750029  [44864/60000]\n",
      "loss: 1.047176  [51264/60000]\n",
      "loss: 0.974062  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.527760 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.824545  [   64/60000]\n",
      "loss: 0.799580  [ 6464/60000]\n",
      "loss: 0.820284  [12864/60000]\n",
      "loss: 0.870684  [19264/60000]\n",
      "loss: 0.842204  [25664/60000]\n",
      "loss: 0.930843  [32064/60000]\n",
      "loss: 0.917665  [38464/60000]\n",
      "loss: 1.035984  [44864/60000]\n",
      "loss: 0.852522  [51264/60000]\n",
      "loss: 0.795703  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.500848 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.739751  [   64/60000]\n",
      "loss: 0.766000  [ 6464/60000]\n",
      "loss: 0.820816  [12864/60000]\n",
      "loss: 0.924688  [19264/60000]\n",
      "loss: 0.693669  [25664/60000]\n",
      "loss: 0.960384  [32064/60000]\n",
      "loss: 0.841578  [38464/60000]\n",
      "loss: 0.830281  [44864/60000]\n",
      "loss: 0.926899  [51264/60000]\n",
      "loss: 0.851555  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.473150 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.850586  [   64/60000]\n",
      "loss: 0.722001  [ 6464/60000]\n",
      "loss: 0.889741  [12864/60000]\n",
      "loss: 0.974820  [19264/60000]\n",
      "loss: 0.657856  [25664/60000]\n",
      "loss: 0.805201  [32064/60000]\n",
      "loss: 0.816502  [38464/60000]\n",
      "loss: 0.934280  [44864/60000]\n",
      "loss: 0.983072  [51264/60000]\n",
      "loss: 0.682578  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.454138 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.865961  [   64/60000]\n",
      "loss: 0.795030  [ 6464/60000]\n",
      "loss: 0.631759  [12864/60000]\n",
      "loss: 0.924792  [19264/60000]\n",
      "loss: 0.794246  [25664/60000]\n",
      "loss: 0.831534  [32064/60000]\n",
      "loss: 1.013368  [38464/60000]\n",
      "loss: 0.933879  [44864/60000]\n",
      "loss: 0.702821  [51264/60000]\n",
      "loss: 0.736166  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.435955 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.789329  [   64/60000]\n",
      "loss: 0.703465  [ 6464/60000]\n",
      "loss: 0.958916  [12864/60000]\n",
      "loss: 0.762549  [19264/60000]\n",
      "loss: 0.652198  [25664/60000]\n",
      "loss: 0.755241  [32064/60000]\n",
      "loss: 0.697114  [38464/60000]\n",
      "loss: 0.943442  [44864/60000]\n",
      "loss: 0.595712  [51264/60000]\n",
      "loss: 0.823459  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.429054 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.775059  [   64/60000]\n",
      "loss: 0.736297  [ 6464/60000]\n",
      "loss: 0.883303  [12864/60000]\n",
      "loss: 0.696461  [19264/60000]\n",
      "loss: 0.901665  [25664/60000]\n",
      "loss: 0.610102  [32064/60000]\n",
      "loss: 0.810193  [38464/60000]\n",
      "loss: 0.806900  [44864/60000]\n",
      "loss: 0.825903  [51264/60000]\n",
      "loss: 0.847622  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.415198 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.627835  [   64/60000]\n",
      "loss: 0.635416  [ 6464/60000]\n",
      "loss: 0.637279  [12864/60000]\n",
      "loss: 0.624357  [19264/60000]\n",
      "loss: 0.803730  [25664/60000]\n",
      "loss: 0.740595  [32064/60000]\n",
      "loss: 0.739268  [38464/60000]\n",
      "loss: 0.808612  [44864/60000]\n",
      "loss: 0.559541  [51264/60000]\n",
      "loss: 0.708511  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.407081 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.900771  [   64/60000]\n",
      "loss: 0.836491  [ 6464/60000]\n",
      "loss: 0.662182  [12864/60000]\n",
      "loss: 0.847003  [19264/60000]\n",
      "loss: 0.575247  [25664/60000]\n",
      "loss: 0.760718  [32064/60000]\n",
      "loss: 0.713484  [38464/60000]\n",
      "loss: 0.731830  [44864/60000]\n",
      "loss: 0.708141  [51264/60000]\n",
      "loss: 0.786392  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.400468 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.454637  [   64/60000]\n",
      "loss: 0.621865  [ 6464/60000]\n",
      "loss: 0.599975  [12864/60000]\n",
      "loss: 0.657435  [19264/60000]\n",
      "loss: 0.500019  [25664/60000]\n",
      "loss: 0.724377  [32064/60000]\n",
      "loss: 0.488725  [38464/60000]\n",
      "loss: 0.684933  [44864/60000]\n",
      "loss: 0.566567  [51264/60000]\n",
      "loss: 0.706483  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.391752 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.664546  [   64/60000]\n",
      "loss: 0.965406  [ 6464/60000]\n",
      "loss: 0.817648  [12864/60000]\n",
      "loss: 0.576073  [19264/60000]\n",
      "loss: 0.737465  [25664/60000]\n",
      "loss: 0.662859  [32064/60000]\n",
      "loss: 0.709812  [38464/60000]\n",
      "loss: 0.810812  [44864/60000]\n",
      "loss: 0.598351  [51264/60000]\n",
      "loss: 0.589779  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.391451 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.613297  [   64/60000]\n",
      "loss: 0.642368  [ 6464/60000]\n",
      "loss: 0.660916  [12864/60000]\n",
      "loss: 0.729962  [19264/60000]\n",
      "loss: 0.830628  [25664/60000]\n",
      "loss: 0.648527  [32064/60000]\n",
      "loss: 0.778263  [38464/60000]\n",
      "loss: 0.890793  [44864/60000]\n",
      "loss: 0.761113  [51264/60000]\n",
      "loss: 0.649939  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.382701 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.834827  [   64/60000]\n",
      "loss: 0.746286  [ 6464/60000]\n",
      "loss: 0.623734  [12864/60000]\n",
      "loss: 0.592732  [19264/60000]\n",
      "loss: 0.517837  [25664/60000]\n",
      "loss: 0.585761  [32064/60000]\n",
      "loss: 0.638230  [38464/60000]\n",
      "loss: 0.740069  [44864/60000]\n",
      "loss: 0.617812  [51264/60000]\n",
      "loss: 0.622104  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.386103 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.575953  [   64/60000]\n",
      "loss: 0.668364  [ 6464/60000]\n",
      "loss: 0.617673  [12864/60000]\n",
      "loss: 0.661512  [19264/60000]\n",
      "loss: 0.831772  [25664/60000]\n",
      "loss: 0.698840  [32064/60000]\n",
      "loss: 0.672738  [38464/60000]\n",
      "loss: 0.738980  [44864/60000]\n",
      "loss: 0.752767  [51264/60000]\n",
      "loss: 0.858201  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.371718 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.613534  [   64/60000]\n",
      "loss: 0.656374  [ 6464/60000]\n",
      "loss: 0.508257  [12864/60000]\n",
      "loss: 0.831199  [19264/60000]\n",
      "loss: 0.946519  [25664/60000]\n",
      "loss: 0.751732  [32064/60000]\n",
      "loss: 0.689719  [38464/60000]\n",
      "loss: 0.538047  [44864/60000]\n",
      "loss: 0.840189  [51264/60000]\n",
      "loss: 0.499327  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.372371 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.791336  [   64/60000]\n",
      "loss: 0.496555  [ 6464/60000]\n",
      "loss: 0.753948  [12864/60000]\n",
      "loss: 0.601428  [19264/60000]\n",
      "loss: 0.654336  [25664/60000]\n",
      "loss: 0.627719  [32064/60000]\n",
      "loss: 0.594393  [38464/60000]\n",
      "loss: 0.506148  [44864/60000]\n",
      "loss: 0.846272  [51264/60000]\n",
      "loss: 0.671701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.361721 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.784063  [   64/60000]\n",
      "loss: 0.534558  [ 6464/60000]\n",
      "loss: 0.523058  [12864/60000]\n",
      "loss: 0.647206  [19264/60000]\n",
      "loss: 0.482012  [25664/60000]\n",
      "loss: 0.634256  [32064/60000]\n",
      "loss: 0.729214  [38464/60000]\n",
      "loss: 0.618057  [44864/60000]\n",
      "loss: 0.750903  [51264/60000]\n",
      "loss: 0.816573  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.354893 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.526882  [   64/60000]\n",
      "loss: 0.776253  [ 6464/60000]\n",
      "loss: 0.893879  [12864/60000]\n",
      "loss: 0.706723  [19264/60000]\n",
      "loss: 0.640831  [25664/60000]\n",
      "loss: 0.728486  [32064/60000]\n",
      "loss: 0.630353  [38464/60000]\n",
      "loss: 0.576249  [44864/60000]\n",
      "loss: 0.534325  [51264/60000]\n",
      "loss: 0.595974  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.356602 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.927643  [   64/60000]\n",
      "loss: 0.689937  [ 6464/60000]\n",
      "loss: 0.823066  [12864/60000]\n",
      "loss: 0.614632  [19264/60000]\n",
      "loss: 0.669387  [25664/60000]\n",
      "loss: 0.647814  [32064/60000]\n",
      "loss: 0.530760  [38464/60000]\n",
      "loss: 0.633168  [44864/60000]\n",
      "loss: 0.617836  [51264/60000]\n",
      "loss: 0.578326  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.350447 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.610055  [   64/60000]\n",
      "loss: 0.570429  [ 6464/60000]\n",
      "loss: 0.550099  [12864/60000]\n",
      "loss: 0.794011  [19264/60000]\n",
      "loss: 0.416797  [25664/60000]\n",
      "loss: 0.712858  [32064/60000]\n",
      "loss: 0.703233  [38464/60000]\n",
      "loss: 0.455638  [44864/60000]\n",
      "loss: 0.579585  [51264/60000]\n",
      "loss: 0.969817  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.348064 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.649972  [   64/60000]\n",
      "loss: 0.719731  [ 6464/60000]\n",
      "loss: 0.589956  [12864/60000]\n",
      "loss: 0.683416  [19264/60000]\n",
      "loss: 0.642987  [25664/60000]\n",
      "loss: 0.591222  [32064/60000]\n",
      "loss: 0.598558  [38464/60000]\n",
      "loss: 0.628349  [44864/60000]\n",
      "loss: 0.613892  [51264/60000]\n",
      "loss: 0.956932  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.342241 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.695088  [   64/60000]\n",
      "loss: 0.624094  [ 6464/60000]\n",
      "loss: 0.611270  [12864/60000]\n",
      "loss: 0.657432  [19264/60000]\n",
      "loss: 0.683731  [25664/60000]\n",
      "loss: 1.101842  [32064/60000]\n",
      "loss: 0.668719  [38464/60000]\n",
      "loss: 0.593601  [44864/60000]\n",
      "loss: 0.630297  [51264/60000]\n",
      "loss: 0.633563  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.340310 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.574138  [   64/60000]\n",
      "loss: 0.777159  [ 6464/60000]\n",
      "loss: 0.552841  [12864/60000]\n",
      "loss: 0.546095  [19264/60000]\n",
      "loss: 0.733516  [25664/60000]\n",
      "loss: 0.583344  [32064/60000]\n",
      "loss: 0.511044  [38464/60000]\n",
      "loss: 0.564909  [44864/60000]\n",
      "loss: 0.673576  [51264/60000]\n",
      "loss: 0.664396  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.337519 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.498854  [   64/60000]\n",
      "loss: 0.475431  [ 6464/60000]\n",
      "loss: 0.406237  [12864/60000]\n",
      "loss: 0.708435  [19264/60000]\n",
      "loss: 0.509548  [25664/60000]\n",
      "loss: 0.526605  [32064/60000]\n",
      "loss: 0.627876  [38464/60000]\n",
      "loss: 0.576530  [44864/60000]\n",
      "loss: 0.496698  [51264/60000]\n",
      "loss: 0.623945  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.338128 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.721928  [   64/60000]\n",
      "loss: 0.589072  [ 6464/60000]\n",
      "loss: 0.710350  [12864/60000]\n",
      "loss: 0.698837  [19264/60000]\n",
      "loss: 0.646218  [25664/60000]\n",
      "loss: 0.642268  [32064/60000]\n",
      "loss: 0.555413  [38464/60000]\n",
      "loss: 0.656280  [44864/60000]\n",
      "loss: 0.545864  [51264/60000]\n",
      "loss: 0.684344  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.342913 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.674159  [   64/60000]\n",
      "loss: 0.485916  [ 6464/60000]\n",
      "loss: 0.559915  [12864/60000]\n",
      "loss: 0.452587  [19264/60000]\n",
      "loss: 0.568130  [25664/60000]\n",
      "loss: 0.643936  [32064/60000]\n",
      "loss: 0.563565  [38464/60000]\n",
      "loss: 0.614955  [44864/60000]\n",
      "loss: 0.683774  [51264/60000]\n",
      "loss: 0.789453  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.332954 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.539738  [   64/60000]\n",
      "loss: 0.523693  [ 6464/60000]\n",
      "loss: 0.596879  [12864/60000]\n",
      "loss: 0.633082  [19264/60000]\n",
      "loss: 0.753469  [25664/60000]\n",
      "loss: 0.574387  [32064/60000]\n",
      "loss: 0.472609  [38464/60000]\n",
      "loss: 0.646434  [44864/60000]\n",
      "loss: 0.685583  [51264/60000]\n",
      "loss: 0.690995  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.330848 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.687309  [   64/60000]\n",
      "loss: 0.552234  [ 6464/60000]\n",
      "loss: 0.618781  [12864/60000]\n",
      "loss: 0.669242  [19264/60000]\n",
      "loss: 0.487247  [25664/60000]\n",
      "loss: 0.537081  [32064/60000]\n",
      "loss: 0.676904  [38464/60000]\n",
      "loss: 0.626651  [44864/60000]\n",
      "loss: 0.514194  [51264/60000]\n",
      "loss: 0.741611  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.331588 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.734228  [   64/60000]\n",
      "loss: 0.574483  [ 6464/60000]\n",
      "loss: 0.451343  [12864/60000]\n",
      "loss: 0.654606  [19264/60000]\n",
      "loss: 0.424358  [25664/60000]\n",
      "loss: 0.801241  [32064/60000]\n",
      "loss: 0.577131  [38464/60000]\n",
      "loss: 0.738068  [44864/60000]\n",
      "loss: 0.545811  [51264/60000]\n",
      "loss: 0.616149  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.325735 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    l1 = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    l2 = test(test_dataloader, model, loss_fn)\n",
    "    wandb.log({\"accuracy_test\": l2[1], \"loss_train\": l1, \"loss_test\":l2[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
