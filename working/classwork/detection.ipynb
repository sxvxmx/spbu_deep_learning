{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aa6323-7c67-44e8-99a0-7857527a9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import tqdm\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import albumentations.pytorch\n",
    "from glob import glob\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e5f2c-fd8a-4cbd-bf84-125a2f064578",
   "metadata": {},
   "source": [
    "В этот раз мы познакомимся с задачей детекции. Сделаем это, обучив модель YOLOv5. Это далеко не самая современная модель, но она достаточно близка к тем, которые используются сейчас.\n",
    "\n",
    "Всего есть два типа моделей детекции: двухэтапные и одноэтапные. Несколько примеров моделей, использующих разные подходы:\n",
    "- RCNN подход: Предполагает двухэтапный проход модели по изображению, где изначально выделяются зоны способами классического компьютерного зрения, а затем происходит уже знакомая нам классификация объектов в зонах и предсказание с помощью задачи регрессии координат box для объектов. \n",
    "- YOLO подход: Одноэтапный детектор удаляет процесс извлечения области интереса и напрямую классифицирует и регрессирует анкерные блоки-кандидаты (anchor-boxes). YOLO — это архитектура детекции, которая называется YOU ONLY LOOK ONCE.Она обучается от от начала до конца, для обработки изображения и прогнозирования ограничивающих рамок (BBox) и меток классов для каждой ограничивающей рамки напрямую. Наверное, наиболее популярная, также лицензия предполгает постоянное появление новых моделей\n",
    "- Detr - также одноэтапный, однако использующий трансформерную архитектуру и особенный дизайн предсказывающей головы, чтобы уйти от необходимости предсказания анкерных блоков (что довольно затратно), предсказывая объекты сразу. Иронично, но в поздних версиях к анкерам вернулись.\n",
    "\n",
    "![alt_text](../additional_materials/images/detection_stages.jfif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ec2167-5e5d-495f-b72a-711cdc83699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (3.1.43)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 7)) (1.26.4)\n",
      "Collecting opencv-python>=4.1.1 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 8))\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 9)) (10.3.0)\n",
      "Requirement already satisfied: psutil in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 10)) (5.9.8)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 11)) (6.0.1)\n",
      "Collecting requests>=2.32.2 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 13)) (1.13.0)\n",
      "Collecting thop>=0.1.1 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 16)) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 17)) (4.66.5)\n",
      "Collecting ultralytics>=8.2.34 (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18))\n",
      "  Downloading ultralytics-8.3.28-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2.2.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 28)) (0.13.2)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 42)) (70.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from requests>=2.32.2->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 12)) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (12.6.68)\n",
      "Collecting py-cpuinfo (from ultralytics>=8.2.34->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18))\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 18))\n",
      "  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from pandas>=1.1.4->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 27)) (2024.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from jinja2->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mchin/Documents/projects/Python/ml/.venv/lib64/python3.12/site-packages (from sympy->torch>=1.8.0->-r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt (line 15)) (1.3.0)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading ultralytics-8.3.28-py3-none-any.whl (881 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, requests, opencv-python, ultralytics-thop, thop, ultralytics\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed opencv-python-4.10.0.84 py-cpuinfo-9.0.0 requests-2.32.3 thop-0.1.1.post2209072238 ultralytics-8.3.28 ultralytics-thop-2.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acce64e-913c-4de7-926c-1ac42d64704c",
   "metadata": {},
   "source": [
    "Для начала посмотрим, как модель строит свои предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ae82a-929f-45ea-b842-05626d70b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "im = \"https://ultralytics.com/images/zidane.jpg\"\n",
    "\n",
    "for f in \"zidane.jpg\", \"bus.jpg\":\n",
    "    torch.hub.download_url_to_file(\"https://ultralytics.com/images/\" + f, f)  # download 2 images\n",
    "im1 = Image.open(\"zidane.jpg\")  # PIL image\n",
    "im2 = cv2.imread(\"bus.jpg\")[..., ::-1]  # OpenCV image (BGR to RGB)\n",
    "\n",
    "results = model([im1, im2], size=640)  # batch of images\n",
    "results.print()\n",
    "results.show()\n",
    "\n",
    "results.xyxy[0]\n",
    "results.pandas().xyxy[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c5473-30fd-4c6b-8317-b9cada4043df",
   "metadata": {},
   "source": [
    "Другой способ загрузить предобученную модель - загрузить с хаба YOLO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f33b43b-68df-4e0e-89ce-afac5f25a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:02<00:00, 1.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd34812-a07a-474f-aac3-6b0cd78e4831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 persons, 1 tie, 118.8ms\n",
      "1: 640x640 4 persons, 1 bus, 118.8ms\n",
      "Speed: 5.9ms preprocess, 118.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model([im1, im2])  # batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7381146f-151d-4e1d-aec5-e8b59d876537",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].show()# Выведите новые результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c6a90e3-29a4-4783-88b6-59a0f46af172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "detections = sv.Detections.from_ultralytics(results[0])\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)\n",
    "\n",
    "annotated_image = im1.copy()\n",
    "annotated_image = box_annotator.annotate(annotated_image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(annotated_image, size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d6f76-1bf9-4c58-b1da-774e6a93ebb1",
   "metadata": {},
   "source": [
    "Как устроена модель: \n",
    "\n",
    "- **Backbone** - это основная часть сети. Для YOLOv5 бекбон спроектирован с использованием CSP-Darknet53 — модификации архитектуры Darknet, использовавшейся в предыдущих версиях.\n",
    "- **Neck**: Эта часть соединяет backbone и head. В YOLOv5 используются структуры SPPF и New CSP-PAN.\n",
    "- **Head**: Эта часть отвечает за конечный результат. Она генерирует предсказанные bbox-ы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c22efd-f6b7-42cc-a36c-650f13b1ec27",
   "metadata": {},
   "source": [
    "У YOLO длинная история. Рассмотрим некоторые основные идеи. \n",
    "![alt_text](../additional_materials/images/yolo_evolution.png)\n",
    "\n",
    "Мы сегодня рассмотрим основные вещи YOLOv5, попробуем ее и YOLOv11. \n",
    "Итак, общая архитектура YOLOv5 показана ниже:\n",
    "![alt_text](../additional_materials/images/YOLOv5-1.png).\n",
    "\n",
    "Какие важные идеи были использованы? \n",
    "Первое - SCPNet (Cross Stage Partial Network). Это важная часть, которая довольно долго тянется в YOLO для того, чтобы управлять протеканием градиентов. Чуть раньше перед этим была придумана DenseNet как ультра-версия резнета ( все блоки соединены со всеми), и из нее выросла идея конкатенировать выходы блоков с более поздними. Это было добавлено в YOLO4, показало эффективность и используется в некотором виде до сих пор. \n",
    "\n",
    "![alt_text](../additional_materials/images/yolo_back.png).\n",
    "\n",
    "Второе - Spatial Pyramid pooling. Этот вид пулинга берет входы с разных этапов прохода по сети и объединяет ыместе конкатенацией, что похволяет находить объекты разных размеров.\n",
    "\n",
    "![alt_text](../additional_materials/images/sppf.jfif)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d284a-bd2f-4078-85d8-6b8defc3ddad",
   "metadata": {},
   "source": [
    "Обучение проводится за один шаг, а не в несколько этапов. В YOLOv5 функция лосса была следующей:\n",
    "![alt_text](../additional_materials/images/det_loss.svg)\n",
    "\n",
    "Она содержит: \n",
    "- Classes Loss (BCE Loss): Бинарная кросс-энтропия для классификации категорий\n",
    "- Objectness Loss (BCE Loss): Еще одна кросс-энтропия, которая позволяет определить, есть ли объект в предсказанном bbox-е.\n",
    "- Location Loss (CIoU Loss): Complete IoU loss, определяет ошибку локализации в гриде\n",
    "Кроме того, функция потерь взвешивается для разных размеров объектов: $L = w_{big} * L_{big} + w_{medium} * L_{medium} + w_{small} * L_{small} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a0c24-617c-4f3c-9133-233c4d0a31ca",
   "metadata": {},
   "source": [
    "Как строятся обучающие датасеты? У YOLO свой формат,описывающий изображения следующим образом: \n",
    "Рассмотрим пример картинки: \n",
    "\n",
    "![alt_text](../additional_materials/images/two-persons-tie.avif)\n",
    "\n",
    "Она содержит два объекта. Каждому из них соответствует bbox и класс. \n",
    "Они сохраняются в файл с разметкой вида: \n",
    "<img src=\"../additional_materials/images/two-persons-tie-1.avif\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Датасет же организуется так как указано ниже:\n",
    "```\n",
    "../datasets/coco128/images/im0.jpg  # image\n",
    "../datasets/coco128/labels/im0.txt  # label\n",
    "```\n",
    "Другой часто использующийся формат датасета - COCO. Пример ниже:\n",
    "```json\n",
    "{\n",
    "    \"info\": {\n",
    "        \"description\": \"COCO 2017 Dataset\",\n",
    "        \"url\": \"http://cocodataset.org\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"year\": 2017,\n",
    "        \"contributor\": \"COCO Consortium\",\n",
    "        \"date_created\": \"2017/09/01\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\"url\": \"http://creativecommons.org/licenses/by/2.0/\",\"id\": 4,\"name\": \"Attribution License\"}\n",
    "    ],\n",
    "    \"images\": [\n",
    "        {\"id\": 242287, \"license\": 4, \"coco_url\": \"http://images.cocodataset.org/val2017/xxxxxxxxxxxx.jpg\", \"flickr_url\": \"http://farm3.staticflickr.com/2626/xxxxxxxxxxxx.jpg\", \"width\": 426, \"height\": 640, \"file_name\": \"xxxxxxxxx.jpg\", \"date_captured\": \"2013-11-15 02:41:42\"},\n",
    "        {\"id\": 245915, \"license\": 4, \"coco_url\": \"http://images.cocodataset.org/val2017/nnnnnnnnnnnn.jpg\", \"flickr_url\": \"http://farm1.staticflickr.com/88/xxxxxxxxxxxx.jpg\", \"width\": 640, \"height\": 480, \"file_name\": \"nnnnnnnnnn.jpg\", \"date_captured\": \"2013-11-18 02:53:27\"}\n",
    "    ],\n",
    "    \"annotations\": [\n",
    "        {\"id\": 125686, \"category_id\": 0, \"iscrowd\": 0, \"segmentation\": [[164.81, 417.51,......167.55, 410.64]], \"image_id\": 242287, \"area\": 42061.80340000001, \"bbox\": [19.23, 383.18, 314.5, 244.46]},\n",
    "        {\"id\": 1409619, \"category_id\": 0, \"iscrowd\": 0, \"segmentation\": [[376.81, 238.8,........382.74, 241.17]], \"image_id\": 245915, \"area\": 3556.2197000000015, \"bbox\": [399, 251, 155, 101]},\n",
    "        {\"id\": 1410165, \"category_id\": 1, \"iscrowd\": 0, \"segmentation\": [[486.34, 239.01,..........495.95, 244.39]], \"image_id\": 245915, \"area\": 1775.8932499999994, \"bbox\": [86, 65, 220, 334]}\n",
    "    ],\n",
    "    \"categories\": [\n",
    "        {\"supercategory\": \"speaker\",\"id\": 0,\"name\": \"echo\"},\n",
    "        {\"supercategory\": \"speaker\",\"id\": 1,\"name\": \"echo dot\"}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03377157-4807-423b-b183-bb92518a6b9f",
   "metadata": {},
   "source": [
    "Как модели обучают? Можно, как обычно в torch, создать датасет и обучить модель, используя кастомные лоссы. Впрочем, в ultralitics есть готовые функции для этого, нужно лишь подготовить датасет.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc9511-f548-40c8-9136-1be9e90f24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d2ee9-e05c-4e5a-b936-f3bf5afac986",
   "metadata": {},
   "source": [
    "Загрузим датасет. Это датасет, содержащий объекты и персонажей apex legends. Этот датасет - один из публичных датасетов roboflow, воспользуемся им."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a24a0-a0af-409a-a7bd-0326564a5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR KEY\")\n",
    "project = rf.workspace(\"roboflow-100\").project(\"apex-videogame\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443efe5-2aad-460c-854d-7a45da16e588",
   "metadata": {},
   "source": [
    "Дообучим модель. Обучать ее с нуля для нас нет смысла. Попробуем дообучить 2 эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf10ad1-cb34-496d-865e-3f5be8b16447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.train(data=\"apex-videogame-2/data.yaml\", epochs=2, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9397554-5f01-4b6c-a23e-cb4377433172",
   "metadata": {},
   "source": [
    "Обратите внимание, как быстро обучается модель. Большой плюс YOLO - ее быстродействие. Результаты обучения сохраняются в файлы, их можно посмотреть после обучения. Посмотрим же. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f813701-49ee-4921-9f60-5a1c5d52986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "filename = r\"D:\\projects\\spbu_deep_learning\\notebooks\\runs\\detect\\train4\\results.png\"\n",
    "IPyImage(filename=filename, width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05e30b-9c6c-403a-9a7b-a5c075e68f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = r\"D:\\projects\\spbu_deep_learning\\notebooks\\runs\\detect\\train4\\val_batch0_pred.jpg\"\n",
    "IPyImage(filename=filename, width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30d468-51f1-446c-be3f-0f2404c2883e",
   "metadata": {},
   "source": [
    "Провалидируем модель: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2924e73-bea5-4c4d-b268-1d1f50491db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=val model=\"D:\\projects\\spbu_deep_learning\\notebooks\\runs\\detect\\train4\\weights\\best.pt\" data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301caa3-2ee5-43d4-a090-6d1f32172bca",
   "metadata": {},
   "source": [
    "Задание: сделайте инференс модели на тестовых данных. Напишите функцию инференса и вывод результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69497500-e500-48c8-a819-876bea0c4f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
