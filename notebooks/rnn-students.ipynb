{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4eda323-3063-435f-bc1a-b1446b014c1c",
   "metadata": {},
   "source": [
    "# Простейшая рекуррентная сеть\n",
    "В этом ноутбуке мы пройдемся по основам работы с RNN. Сегодня займемся задачей генерации текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8b089-5f9c-4dcb-8b14-3f565c24e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, Tuple\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198424b3-07c0-4b46-83f0-8bbb53acacd4",
   "metadata": {},
   "source": [
    "В качестве обучающего датасета возьмем набор из 120 тысяч анекдотов на русском языке. \n",
    "[Ссылка на данные](https://archive.org/download/120_tysyach_anekdotov) и [пост на хабре про тематическое моделирование](https://habr.com/ru/companies/otus/articles/723306/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fda8b3-2e4b-4385-aad5-b10ad73a5d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\data\\spbu_dl\\120_tysyach_anekdotov\\anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text[118:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f21a5-c7e3-445f-b902-24e18242bd7b",
   "metadata": {},
   "source": [
    "Мы не хотим моделировать все подряд, поэтому разобьем датасет на отдельные анекдоты.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd3f65-a156-4bbd-8c56-078652d38ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(text):\n",
    "    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae42013-ef71-485c-805e-8cc4c61fe6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text = cut_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8e214-e40c-4705-beb4-f51a6a284137",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_text[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f6226-74c6-4488-a7bc-9360437e1b1f",
   "metadata": {},
   "source": [
    "Сделаем для начала самую простую модель с токенами на уровне символов. Это значит, что каждому символу в тексте ставится в соответствие некоторое число. Некоторые способы токенизации используют части слов или, наоборот, части бинарного представления текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e923efb-a3d5-4e22-b8e0-8bf6260d1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = tuple(set(text))\n",
    "int2char = dict(enumerate(unique_chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fa447-208d-4285-bb76-0870e985ce58",
   "metadata": {},
   "source": [
    "Напишем функции для энкодинга и декодинга нашего текста. Они будут преобразовывать список символов в список чисел и обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97704441-98c6-4c16-b0c2-10b88f941c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence, vocab):\n",
    "    return # List of ints \n",
    "\n",
    "def decode(tokens, vocab):\n",
    "    return # list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b4340-44bb-45ab-8cfe-972c9cfd410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверьте, что энеодинг и декодинг работают"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017baeba-1197-4d21-8cc8-28ccf43262c5",
   "metadata": {},
   "source": [
    "Просто представления символов в виде числа не подходят для обучения моделей. На выходе должны быть вероятности всех возможных токенов из словаря. Поэтому модели удобно учить с помощью энтропии. К тому же, токены часто преобразуют из исходного представления в эмбеддинги, которые также позволяют получить более удобное представление в высокоразмерном пространстве. \n",
    "\n",
    "В итоге векторы в модели выглядят следующим образом:\n",
    "![alt_text](../additional_materials/images/char_rnn.jfif)\n",
    "\n",
    "Задание: реализуйте метод, который преобразует батч в бинарное представление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692112f-edea-4e18-b48b-5aec75f935d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(int_words: torch.Tensor, vocab_size: int) -> torch.Tensor:\n",
    "    \"\"\"Encodes batch of sentences into binary values\"\"\"\n",
    "    words_one_hot = torch.zeros(\n",
    "        # init one hot tensor. \n",
    "    )\n",
    "    # your code: make from int one hot vector for each element of input tensor. Size bxseq_len -> b x seq_len x vocab_size\n",
    "    return words_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88488683-6df3-430e-b942-9c10548a1802",
   "metadata": {},
   "source": [
    "Проверьте ваш код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af941c64-cc6d-41b4-92e3-a8f37b861545",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.tensor([[2, 6, 4, 1], [0,3, 2, 4]])\n",
    "test_one_hot = one_hot_encode(test_seq, 8)\n",
    "\n",
    "print(test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da82134-e59d-4806-be2c-839c2f850ee6",
   "metadata": {},
   "source": [
    "Однако, наши последовательности на самом деле разной длины. Как же объединить их в батч?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0fe1e-40a5-4a58-b1bd-b4a4101d986a",
   "metadata": {},
   "source": [
    "Реализуем два необходимых класса: \n",
    "- токенайзер, который будет брать текст, кодировать и декодировать символы. Еще одно, что будет реализовано там - добавлено несколько специальных символов (паддинг, конец последовательности, начало последовательности).\n",
    "- Датасет, который будет брать набор шуток, используя токенайзер, строить эмбеддинги и дополнять последовательность до максимальной длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d266c8-b4d0-42fd-9c6c-02b7f3b9a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, cut_text, max_len: int = 512):\n",
    "        self.text = text\n",
    "        self.max_len = max_len\n",
    "        self.specials = ['<pad>', '<bos>', '<eos>']\n",
    "        unique_chars = tuple(set(text))\n",
    "        self.int2char = dict(enumerate(tuple(set(text))))\n",
    "        self.char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "        self._add_special(\"<pad>\")\n",
    "        self._add_special('<bos>')\n",
    "        self._add_special('<eos>')\n",
    "    \n",
    "    def _add_special(self, symbol) -> None:\n",
    "        # add special characters to yuor dicts\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return # your code\n",
    "        \n",
    "    def decode_symbol(self, el):\n",
    "        return self.int2char[el]\n",
    "        \n",
    "    def encode_symbol(self, el):\n",
    "        return self.char2int[el]\n",
    "        \n",
    "    def str_to_idx(self, chars):\n",
    "        return # str -> list[int]\n",
    "\n",
    "    def idx_to_str(self, idx):\n",
    "        return # list[int] -> list[str\n",
    "\n",
    "    def encode(self, chars):\n",
    "        chars = ['<bos>'] + list(chars) + ['<eos>']\n",
    "        return self.str_to_idx(chars)\n",
    "\n",
    "    def decode(self, idx):\n",
    "        chars = self.idx_to_str(idx)\n",
    "        return # make string from list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a76399-0ae4-4d4f-9d95-56d695eb7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokesDataset(Dataset):\n",
    "    def __init__(self, tokenizer, cut_text, max_len: int = 512):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cut_text = cut_text\n",
    "        self.pad_index = self.tokenizer.encode_symbol(\"<pad>\")\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        # pad your sequence and make a final sample. You can skip padding and pad sequences with torch special method.\n",
    "        return padded, len(encoded)\n",
    "\n",
    "# Optionally add new methods to your dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e66a2-d196-459f-a88a-94bc119873e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(text)\n",
    "dataset = JokesDataset(tokenizer, cut_text, 512)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72173d-d38b-4d4c-a98e-878267c0fd87",
   "metadata": {},
   "source": [
    "Вопрос: А как бы мы должны были разделять данные на последовательности и батчи в случае, если бы использовался сплошной текст?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182387e9-9768-42b2-b428-16d73b24b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание: проверьте свой датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf1f16-53d0-45a6-abd5-1a4c5b17285f",
   "metadata": {},
   "source": [
    "Теперь реализуем нашу модель. \n",
    "Необходимо следующее:\n",
    " - Используя токенайзер, задать размер словаря\n",
    " - Задать слой RNN с помощью torch.RNN. Доп.задание: создайте модель, используя слой LSTM.\n",
    " - Задать полносвязный слой с набором параметров: размерность ввода — n_hidden; размерность выхода — размер словаря. Этот слой преобразует состояние модели в логиты токенов.\n",
    " - Определить шаг forward, который будет использоваться при обучении\n",
    " - Определить метод init_hidden, который будет задавать начальное внутреннее состояние. Инициализировать будем нулями.\n",
    " - Определить метод inference, в котором будет происходить генерация последовательности из префикса. Здесь мы уже не используем явные логиты, а семплируем токены на их основе.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc03daf-9a78-4d34-a8da-c1aed594b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 2,\n",
    "        drop_prob: float = 0.5,\n",
    "        max_len: int = 512,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.max_len = max_len\n",
    "        # create mappings\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        ## define the LSTM, dropout and fully connected layers\n",
    "        self.rnn = # your code\n",
    "        self.dropout = # your code\n",
    "        self.fc = # your code\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, lengths: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # one-hot encode your sequence\n",
    "        packed_embeds = # pack your sequence. This helps with the efficiency. Use torch function pack_padded_sequence\n",
    "        outputs, hidden = # run you model\n",
    "        out, lengths = # pad sequence back\n",
    "        ## Get the output for classification.\n",
    "        out = \n",
    "        return out\n",
    "\n",
    "    def inference(self, prefix='<bos> ', device=\"cpu\"):\n",
    "        tokens =  # encode prefix\n",
    "        # create embeddings \n",
    "        # generate hidden and logits for prefix\n",
    "               \n",
    "        new_tokens = # sample new token from logits\n",
    "        tokens = torch.cat([tokens, new_tokens], dim=1)\n",
    "\n",
    "        # 2 stopping conditions: reaching max len or getting <eos> token\n",
    "        while tokens.shape[1] < self.max_len:\n",
    "            # YOUR CODE: generate sequence one by one\n",
    "        return self.tokenizer.decode(tokens.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202bfda-3653-4644-8fcc-eda9e92e434f",
   "metadata": {},
   "source": [
    "Зададим параметры для обучения. Можете варьировать их, чтобы вам хватило ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173284d2-1d28-4235-a3ac-e25494039e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_length = 512\n",
    "n_hidden = 64\n",
    "n_layers = 4\n",
    "drop_prob = 0.1\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329823d-abd8-4044-8206-470f07b6da62",
   "metadata": {},
   "source": [
    "Напишите функцию для одного тренировочного шага. В этом ноутбуке сам процесс обучения модели достаточно тривиален, поэтому мы не будем использовать сложные функции для обучающего цикла. Вы же, однако, можете дописать их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cb10c-1da8-43fc-b332-1b53f4fb6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(\n",
    "    model: CharRNN,\n",
    "    train_batch: Tuple[torch.Tensor, torch.Tensor],\n",
    "    vocab_size: int,\n",
    "    criterion: nn.Module,\n",
    "    optimizer,\n",
    "    device=\"cpu\"\n",
    ") -> torch.Tensor:\n",
    "    optimizer.zero_grad()\n",
    "    batch_size, seq_len = train_batch[0].shape\n",
    "    # train step. Ensure the model output and \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055e6e-6374-4af3-b1ab-8ad8b4125664",
   "metadata": {},
   "source": [
    "Инициализируйте модель, функцию потерь и оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fc024-7cec-4833-ac15-cafe05724003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(tokenizer, n_hidden, n_layers, drop_prob)\n",
    "hidden = None\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a140de0c-e648-4d9f-babf-659486dbae92",
   "metadata": {},
   "source": [
    "Проверьте необученную модель: она должна выдавать бессмысленные последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d26fdb-5292-41c4-83df-e8feb3a22561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37263cdf-5a6c-4612-8cf9-57105c169943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    clear_output()\n",
    "    plt.plot(range(1, len(losses) + 1), losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f70324-c88a-4d98-bae6-e6c5356f2025",
   "metadata": {},
   "source": [
    "Проведите обучение на протяжении нескольких эпох и выведите график лоссов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57059744-44ac-4aad-86f6-f67dc2ea7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # your code: run model traininig for n epochs\n",
    "    \n",
    "    plot_losses(losses)\n",
    "    torch.save(model.state_dict(), \"rnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8694a-132f-4a44-a5d3-a0f39219e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.inference(\"\") for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13c3b7-3fde-416b-a766-e6be7c791505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительная секция"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef889dd2-fde2-429c-9c61-f5a93517bd3f",
   "metadata": {},
   "source": [
    "Теперь попробуем написать свой собственный RNN. Это будет довольно простая модель с одним слоем.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe4954-e2b5-43c5-9bb6-0b2a5cc2cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: custom model nn.Module, changed CharRNN, etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spbu_dl",
   "language": "python",
   "name": "spbu_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
